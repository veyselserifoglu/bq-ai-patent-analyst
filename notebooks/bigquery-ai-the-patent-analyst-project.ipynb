{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":110281,"databundleVersionId":13391012,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The AI Patent Analyst: From Unstructured PDFs to a Queryable Knowledge Graph\n\n## 1. High-Level Summary\n\nThis project demonstrates an end-to-end AI pipeline built entirely within Google BigQuery that transforms unstructured patent PDFs into a structured, queryable Knowledge Graph. The final prototype acts as a sophisticated IP analysis tool, enabling deep architectural analysis, component-level semantic search, all using BigQuery AI functions.\n\nThis solution directly addresses the challenge of making sense of messy, mixed-format data that is often overlooked, turning it into a powerful, interactive analytical asset.\n\n## 2. The Workflow: A Multi-Stage AI Pipeline\n\nOur solution follows a three-stage process, showcasing a powerful combination of BigQuery's multimodal, generative, and vector search capabilities.\n\n### Stage 1: Multimodal Data Processing (üñºÔ∏è Pioneer)\nWe use **Object Tables** to directly read and process raw PDFs from Cloud Storage. The Gemini model is then used with `ML.GENERATE_TEXT` to analyze the both the text and the technical diagrams within the PDFs.\n\n### Stage 2: Generative Knowledge Graph Extraction (üß† Architect)\nThe consolidated patent text is fed into the `AI.GENERATE_TABLE` function. A custom prompt instructs the AI to act as an expert analyst, extracting a structured table of high-level insights (`invention_domain`, `problem_solved`) and a detailed, nested graph of all technical components, their functions, and their interconnections.\n\n### Stage 3: Component-Level Semantic Search (üïµÔ∏è‚Äç‚ôÄÔ∏è Detective)\nTo enable deep discovery, we build a novel search engine that understands context. We use `ML.GENERATE_EMBEDDING` to create two separate vectors:\n1.  One for the patent's high-level context (title, abstract)\n2.  Another for each component's specific function\n\nThese vectors are mathematically averaged into a single, final vector for each component via BigQuery's UDF (User-Defined Functions).\n\nFinally, `VECTOR_SEARCH` is used on these combined vectors, creating a powerful search that returns highly relevant, context-aware results.\n\n## 3. Key Features & Analytical Capabilities\n\nThe final `patent_knowledge_graph` table is not just a dataset; it's an interactive analysis engine that can answer questions which are more difficult and time consuming with the original text:\n\n*   **Deep Architectural Analysis:** Use standard SQL with `UNNEST` and `GROUP BY` to discover the most common design patterns and component connections across hundreds of inventions.\n\n*   **Component Search:** Go beyond patent-level search to find specific, functionally similar technical parts across different domains (e.g., \"find a mechanism for encrypting data\").\n\n\n*   **Quantitative Portfolio Analysis:** Compare patent applicants by the complexity (average component count) and breadth (number of domains) of their innovations.\n\n\n## 4. Dataset Overview\n- **403 PDFs** (197 English, others in FR/DE) at `gs://gcs-public-data--labeled-patents/*.pdf`.\n- **Tables**: `extracted_data` (metadata), `invention_types` (labels), `figures` (91 diagram coordinates).\n- **Source**: [Labeled Patents](https://console.cloud.google.com/marketplace/product/global-patents/labeled-patents?inv=1&invt=Ab5j9A&project=bq-ai-patent-analyst&supportedpurview=organizationId,folder,project) (1TB/mo free tier).\n\n## 5. Code\n*   **Notebook & Repository:** [https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/notebooks/bigquery-ai-the-patent-analyst-project.ipynb](https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/notebooks/bigquery-ai-the-patent-analyst-project.ipynb)\n\n## 6. Architecture Pipeline","metadata":{}},{"cell_type":"code","source":"# Display Architecture pipeline\n\nHTML(f'''\n<div style=\"text-align: center; padding: 15px;\">\n    <a href=\"https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/doc/Patent%20Analysis%20Pipeline%20Architecture%20-%20PNG.png?raw=true\" \n       target=\"_blank\" \n       style=\"cursor: pointer; display: inline-block; text-decoration: none;\">\n        <div style=\"position: relative; display: inline-block;\">\n            <img src=\"https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/doc/Patent%20Analysis%20Pipeline%20Architecture%20-%20PNG.png?raw=true\" \n                 width=\"300\" \n                 height=\"200\"\n                 style=\"border: 2px solid #e0e0e0; border-radius: 8px; transition: all 0.3s ease; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\"\n                 onmouseover=\"this.style.borderColor='#4285F4'; this.style.boxShadow='0 6px 12px rgba(66, 133, 244, 0.3)'\"\n                 onmouseout=\"this.style.borderColor='#e0e0e0'; this.style.boxShadow='0 4px 8px rgba(0,0,0,0.1)'\">\n            <div style=\"position: absolute; top: 8px; right: 8px; background: rgba(255,255,255,0.9); border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-size: 14px;\">\n                ‚Üó\n            </div>\n        </div>\n    </a>\n    <p style=\"margin-top: 12px; color: #5f6368; font-size: 13px; font-style: italic;\">Click to explore the full architecture</p>\n</div>\n''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T21:20:34.254168Z","iopub.execute_input":"2025-08-19T21:20:34.254457Z","iopub.status.idle":"2025-08-19T21:20:34.261181Z","shell.execute_reply.started":"2025-08-19T21:20:34.254436Z","shell.execute_reply":"2025-08-19T21:20:34.260271Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<div style=\"text-align: center; padding: 15px;\">\n    <a href=\"https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/doc/Patent%20Analysis%20Pipeline%20Architecture%20-%20PNG.png?raw=true\" \n       target=\"_blank\" \n       style=\"cursor: pointer; display: inline-block; text-decoration: none;\">\n        <div style=\"position: relative; display: inline-block;\">\n            <img src=\"https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/doc/Patent%20Analysis%20Pipeline%20Architecture%20-%20PNG.png?raw=true\" \n                 width=\"300\" \n                 height=\"200\"\n                 style=\"border: 2px solid #e0e0e0; border-radius: 8px; transition: all 0.3s ease; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\"\n                 onmouseover=\"this.style.borderColor='#4285F4'; this.style.boxShadow='0 6px 12px rgba(66, 133, 244, 0.3)'\"\n                 onmouseout=\"this.style.borderColor='#e0e0e0'; this.style.boxShadow='0 4px 8px rgba(0,0,0,0.1)'\">\n            <div style=\"position: absolute; top: 8px; right: 8px; background: rgba(255,255,255,0.9); border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-size: 14px;\">\n                ‚Üó\n            </div>\n        </div>\n    </a>\n    <p style=\"margin-top: 12px; color: #5f6368; font-size: 13px; font-style: italic;\">Click to explore the full architecture</p>\n</div>\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# For visualization purposes\n%pip install -q pyvis\n%pip install -q plotly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T13:37:14.365697Z","iopub.execute_input":"2025-08-19T13:37:14.366001Z","iopub.status.idle":"2025-08-19T13:37:24.865017Z","shell.execute_reply.started":"2025-08-19T13:37:14.365975Z","shell.execute_reply":"2025-08-19T13:37:24.863807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# BigQuery\nimport os\nfrom google.cloud import bigquery\nfrom kaggle_secrets import UserSecretsClient\nimport pandas as pd\nfrom pyvis.network import Network\nimport plotly.express as px\nfrom google.cloud import bigquery\nfrom IPython.display import Image, display, HTML, IFrame","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Google Cloud Project Setup\n\nThis guide outlines the one-time setup required in Google Cloud and Kaggle to enable the analysis.\n\n---\n\n### 1. Google Cloud Project Configuration\n\nFirst, configure your Google Cloud project.\n\n1.  **Select or Create a Project**\n    * Ensure you have a Google Cloud project.\n    * Copy the **Project ID** (e.g., `my-project-12345`), not the project name.\n\n2.  **Enable Required APIs**\n    * In your project, enable the following two APIs:\n        * **Vertex AI API**\n        * **BigQuery Connection API**\n\n3.  **Create a Service Account for the Notebook**\n    * This service account allows the Kaggle notebook to act on your behalf.\n    * Navigate to **IAM & Admin** > **Service Accounts**.\n    * Click **+ CREATE SERVICE ACCOUNT**.\n    * Give it a name (e.g., `kaggle-runner`).\n    * Grant it these three roles:\n        * `BigQuery Admin`\n        * `Vertex AI User`\n        * `Service Usage Admin`\n    * After creating the account, go to > manage keys > create a new key. A file will be downloaded to your computer.\n\n---\n\n### 2. Kaggle Notebook Configuration\n\nNext, configure this Kaggle notebook to use your project.\n\n1.  **Add Kaggle Secrets**\n    * In the notebook editor, go to the **\"Add-ons\"** menu and select **\"Secrets\"**.\n    * Add two secrets:\n        * **`GCP_PROJECT_ID`**: Paste your Google Cloud **Project ID** here.\n        * **`GCP_SA_KEY`**: Open the downloaded JSON key file, copy its entire text content, and paste it here.\n\n---\n\n### 3. Final Permission Step (After Running Code)\n\nThe first time you run the setup cells in the notebook, a new BigQuery connection will be created. This connection has its own unique service account that needs permission to use AI models.\n\n1.  **Find the Connection Service Account**\n    * After running the setup cells, go to **BigQuery** > **External connections** in your Google Cloud project.\n    * Click on the connection named `llm-connection`.\n    * Copy its **Service Account ID** (it will look like `bqcx-...@...gserviceaccount.com`).\n\n2.  **Grant Permission**\n    * Go to the **IAM & Admin** page.\n    * Click **+ Grant Access**.\n    * Paste the connection's service account ID into the **\"New principals\"** box.\n    * Give it the single role of **`Vertex AI User`**.\n    * Click **Save**.\n\n---\n\nWith this setup complete, the notebook has secure access to your Google Cloud project and can run all subsequent analysis cells.","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nproject_id = user_secrets.get_secret(\"GCP_PROJECT_ID\")\ngcp_key_json = user_secrets.get_secret(\"GCP_SA_KEY\")\nlocation = 'US'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T13:37:47.924725Z","iopub.execute_input":"2025-08-19T13:37:47.925491Z","iopub.status.idle":"2025-08-19T13:37:48.091164Z","shell.execute_reply.started":"2025-08-19T13:37:47.925452Z","shell.execute_reply":"2025-08-19T13:37:48.089997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Write the key to a temporary file in the notebook's environment\nkey_file_path = 'gcp_key.json'\ntry:\n    with open(key_file_path, 'w') as f:\n        f.write(gcp_key_json)\n    \n    # Remove \"> /dev/null 2>&1\" to show the output.\n    # Authenticate the gcloud tool using the key file\n    !gcloud auth activate-service-account --key-file={key_file_path} > /dev/null 2>&1\n    \n    # Configure the gcloud tool to use your project\n    !gcloud config set project {project_id} > /dev/null 2>&1\n    \nfinally:\n    # Securely delete the key file immediately after use\n    if os.path.exists(key_file_path):\n        os.remove(key_file_path)\n\n# Enable the Vertex AI and BigQuery Connection APIs. Run only once Or Enable using the Cloud Interface.\n# !gcloud services enable aiplatform.googleapis.com bigqueryconnection.googleapis.com > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T13:37:48.092984Z","iopub.execute_input":"2025-08-19T13:37:48.093304Z","iopub.status.idle":"2025-08-19T13:37:51.641983Z","shell.execute_reply.started":"2025-08-19T13:37:48.093283Z","shell.execute_reply":"2025-08-19T13:37:51.640371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This command creates the connection resource. Remove \"> /dev/null 2>&1\" to show the output.\n!bq mk --connection --location={location} --connection_type=CLOUD_RESOURCE llm-connection > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T13:32:13.704896Z","iopub.execute_input":"2025-08-19T13:32:13.705258Z","iopub.status.idle":"2025-08-19T13:32:17.198616Z","shell.execute_reply.started":"2025-08-19T13:32:13.705228Z","shell.execute_reply":"2025-08-19T13:32:17.196942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This command shows the details of your connection. Remove \"> /dev/null 2>&1\" to show the output.\n!bq show --connection --location={location} llm-connection > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T13:32:18.794911Z","iopub.execute_input":"2025-08-19T13:32:18.795265Z","execution_failed":"2025-08-19T13:32:20.454Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# BigQuery Resource Creation\n\nThis section runs three commands to create the necessary resources for our analysis inside your BigQuery project.\n\n---\n\n### 1. Create a Dataset in the Correct Region\n\nFirst, we create a new dataset named `patent_analysis` in our chosen region. This dataset acts as a container for the AI model and the object table we will create next.\n\n### 2. Create a Reference to the AI Model\n\nNext, we create a \"shortcut\" to Google's `gemini-2.5-flash` model. This command gives us an easy name, `gemini_vision_analyzer`, to use in our analysis queries.\n\n### 3. Create an Object Table for the PDFs\n\nFinally, we create an object table named `patent_documents_object_table`. This is a special \"map\" that points directly to all the raw PDF files in the public Google Cloud Storage bucket, making them ready for analysis.\n\n---","metadata":{}},{"cell_type":"code","source":"client = bigquery.Client(project=project_id, location=location)\nclient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T13:37:51.643289Z","iopub.execute_input":"2025-08-19T13:37:51.643694Z","iopub.status.idle":"2025-08-19T13:37:51.653652Z","shell.execute_reply.started":"2025-08-19T13:37:51.643647Z","shell.execute_reply":"2025-08-19T13:37:51.652594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Create the new dataset in the correct location\ncreate_dataset_query = f\"\"\"\nCREATE SCHEMA IF NOT EXISTS `{project_id}.patent_analysis`\nOPTIONS(location = '{location}');\n\"\"\"\n\nprint(f\"Creating dataset 'patent_analysis' in {location}...\")\njob = client.query(create_dataset_query)\ntry:\n    job.result()\n    print(\"‚úÖ Dataset created successfully or already exists.\")\nexcept Exception as e:\n    print(f\"‚ùå FAILED to create dataset. Error:\\n\\n{e}\")\n\n\n# 2. Create the AI model reference inside the new dataset\ncreate_model_query = f\"\"\"\nCREATE OR REPLACE MODEL `{project_id}.patent_analysis.gemini_vision_analyzer`\n  REMOTE WITH CONNECTION `{location}.llm-connection`\n  OPTIONS (endpoint = 'gemini-2.5-flash');\n\"\"\"\n\nprint(\"\\nCreating the AI model reference...\")\njob = client.query(create_model_query)\ntry:\n    job.result() # This waits for the job to complete.\n    print(\"‚úÖ SUCCESS: Model 'gemini_vision_analyzer' created successfully.\")\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Please share this full error message:\\n\\n{e}\")\n\n# TODO: replace the gcs files source with a variable\n# 3. Create the Object Table\n# This query creates the \"map\" to the PDF files inside the local 'patent_analysis' dataset.\nobject_table_query = f\"\"\"\nCREATE OR REPLACE EXTERNAL TABLE `{project_id}.patent_analysis.patent_documents_object_table`\nWITH CONNECTION `{location}.llm-connection`\nOPTIONS (\n    object_metadata = 'SIMPLE',\n    uris = ['gs://gcs-public-data--labeled-patents/*.pdf'] \n);\n\"\"\"\n\nprint(\"Creating the object table...\")\njob = client.query(object_table_query)\ntry:\n    job.result()\n    print(\"‚úÖ Object table created successfully.\")\nexcept Exception as e:\n    print(f\"‚ùå FAILED to create the object table. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T12:57:54.778150Z","iopub.execute_input":"2025-08-15T12:57:54.778563Z","iopub.status.idle":"2025-08-15T12:57:57.400188Z","shell.execute_reply.started":"2025-08-15T12:57:54.778534Z","shell.execute_reply":"2025-08-15T12:57:57.398141Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Extraction & Knowledge Graph Creation\n\n## What did we build?\nWe created the foundational data asset for this entire project: the `patent_knowledge_graph` table. This involved two major extraction steps.\n\n## Why is this important?\n- The raw patent PDFs are a classic example of \"dark data\"; valuable information that is difficult to query and analyze.\n- This section details how we transformed that messy, unstructured data into a clean, structured table.\n- This unlocks the data, making it possible to perform the deep SQL analysis and advanced semantic search in the later stages of this notebook.\n\n## How did we do it?\nThe process used a sequence of BigQuery's native AI functions:\n\n1. **Multimodal Analysis**:\n   - First, we used `ML.GENERATE_TEXT` to analyze the text and the technical diagrams within each patent's PDF.\n   - Generated rich descriptions of the visual components.\n\n2. **Knowledge Graph Extraction**:\n   - Next, we fed all the consolidated text into the `AI.GENERATE_TABLE` function.\n   - We gave the model a custom prompt, instructing it to act as an expert and extract:\n     - A structured, nested table of all technical components.\n     - Their functions.\n     - Their connections for each patent.","metadata":{}},{"cell_type":"code","source":"# 1. Multimodal Analysis - only texts.\n\nprompt_text = \"\"\"From this patent document, perform the following tasks:\n\n1.  **Extract these fields**: title, inventor, abstract, \n    the **Filed**, the **Date of Patent**, the international classification code, and the applicant.\n    \n2.  **Translate**: If the original title and abstract are in German or French, translate them into English.\n\n3.  **Identify Language**: Determine the original language of the document.\n\nReturn ONLY a valid JSON object with EXACTLY these ten keys: \n\"title_en\", \"inventor\", \"abstract_en\", \"filed\", \"date_of_patent\", \"class_international\", \"applicant\", and \"original_language\".\n\n**Formatting Rule**: For any key that has multiple values (like \"inventor\" or \"class_international\" or \"applicant\"), \ncombine them into a single string, separated by a comma and a space. For example: \"Igor Karp, Lev Stesin\".\n\nThe \"original_language\" value must be one of these three strings: 'EN', 'FR', or 'DE'.\nIf any other field is unavailable, use null as the value.\n\"\"\"\n\n# The main SQL query.\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.ai_text_extraction` AS (\n  WITH raw_json AS (\n      SELECT\n        uri,\n        ml_generate_text_llm_result AS llm_result\n      FROM\n        ML.GENERATE_TEXT(\n          MODEL `{project_id}.patent_analysis.gemini_vision_analyzer`,\n          TABLE `{project_id}.patent_analysis.patent_documents_object_table`,\n          STRUCT(\n            '''{prompt_text}''' AS prompt,\n            2048 AS max_output_tokens,\n            0.2 AS temperature,\n            TRUE AS flatten_json_output\n          )\n        )\n    ),\n    parsed_json AS (\n      -- Step 2: Clean and parse the JSON output.\n      SELECT\n        uri,\n        llm_result,\n        SAFE.PARSE_JSON(\n          REGEXP_REPLACE(llm_result, r'(?s)```json\\\\n(.*?)\\\\n```', r'\\\\1')\n        ) AS json_data\n      FROM\n        raw_json\n    )\n  SELECT\n    uri,\n    llm_result,\n    \n    SAFE.JSON_VALUE(json_data, '$.original_language') AS original_language,\n    SAFE.JSON_VALUE(json_data, '$.title_en') AS extracted_title_en,\n    SAFE.JSON_VALUE(json_data, '$.inventor') AS extracted_inventor,\n    SAFE.JSON_VALUE(json_data, '$.abstract_en') AS extracted_abstract_en,\n    SAFE.JSON_VALUE(json_data, '$.filed') AS filed_date,\n    SAFE.JSON_VALUE(json_data, '$.date_of_patent') AS official_patent_date,\n    SAFE.JSON_VALUE(json_data, '$.class_international') AS class_international,\n    SAFE.JSON_VALUE(json_data, '$.applicant') AS applican\n    \n  FROM\n    parsed_json\n);\n\"\"\"\n\njob = client.query(sql_query)\n\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Multimodal Analysis - only technical diagrams.\n\ndiagram_prompt_text = \"\"\"\nDescribe this technical diagram from a patent document. \nWhat is its primary function and what key components are labeled?\n\"\"\"\n\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.ai_text_extraction` AS (\n\n  WITH figures_with_object_ref AS (\n      SELECT\n        fig.*, obj.ref\n      FROM\n        `bigquery-public-data.labeled_patents.figures` AS fig\n      JOIN\n        `{project_id}.patent_analysis.patent_documents_object_table` AS obj\n      ON\n        fig.gcs_path = obj.uri\n    ),\n    \n    generated_descriptions AS (\n      SELECT\n        gcs_path,\n        ml_generate_text_llm_result AS diagram_description\n      FROM\n        ML.GENERATE_TEXT(\n          MODEL `{project_id}.patent_analysis.gemini_vision_analyzer`,\n          (\n            SELECT\n              gcs_path,\n              [\n                JSON_OBJECT('uri', ref.uri, 'bounding_poly', [\n                  STRUCT(x_relative_min AS x, y_relative_min AS y),\n                  STRUCT(x_relative_max AS x, y_relative_min AS y),\n                  STRUCT(x_relative_max AS x, y_relative_max AS y),\n                  STRUCT(x_relative_min AS x, y_relative_max AS y)\n                ])\n              ] AS contents,\n              '''{diagram_prompt_text}''' AS prompt\n            FROM\n              figures_with_object_ref\n          ),\n          STRUCT(\n            4096 AS max_output_tokens,\n            0.2 AS temperature,\n            TRUE AS flatten_json_output\n          )\n        )\n    ),\n\n    aggregated_descriptions AS (\n      SELECT\n        gcs_path,\n        ARRAY_AGG(diagram_description IGNORE NULLS) AS diagram_descriptions\n      FROM\n        generated_descriptions\n      GROUP BY\n        gcs_path\n    )\n\n  SELECT\n    T.*,\n    S.diagram_descriptions\n  FROM\n    `{project_id}.patent_analysis.ai_text_extraction` AS T\n  LEFT JOIN\n    aggregated_descriptions AS S\n  ON\n    T.uri = S.gcs_path\n);\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T11:00:55.552567Z","iopub.execute_input":"2025-08-17T11:00:55.553247Z","iopub.status.idle":"2025-08-17T11:01:15.152564Z","shell.execute_reply.started":"2025-08-17T11:00:55.553220Z","shell.execute_reply":"2025-08-17T11:01:15.151711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Knowledge Graph Extraction.\n\n# Define the schema as a Python variable\nschema = \"\"\"\ninvention_domain STRING, problem_solved STRING, patent_type STRING, \ncomponents ARRAY<STRUCT<component_name STRING, component_function STRING, connected_to ARRAY<STRING>>>\n\"\"\"\n\n# The prompt text remains the same\nprompt_text = \"\"\"\nFrom the following patent text, perform these tasks:\n1. Determine the high-level technical domain (e.g., 'Telecommunications', 'Medical Devices').\n2. Provide a one-sentence summary of the core problem the invention solves.\n3. Classify the patent as a 'Method', 'System', 'Apparatus', or a combination.\n4. Extract all technical components into a nested list. \nFor each component, provide its name, its primary function, and a list of other components it is connected to.\n\nHere is the text:\n\"\"\"\n\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.patent_knowledge_graph` AS (\n  SELECT\n    t.uri,\n    t.invention_domain,\n    t.problem_solved,\n    t.patent_type,\n    t.components\n  FROM\n    AI.GENERATE_TABLE(\n      MODEL `{project_id}.patent_analysis.gemini_vision_analyzer`,\n      (\n        SELECT\n          uri,\n          CONCAT(\n            '''{prompt_text}''',\n            '\\\\n\\\\n',\n            IFNULL(extracted_title_en, ''),\n            '\\\\n\\\\n',\n            IFNULL(extracted_abstract_en, ''),\n            '\\\\n\\\\nDiagrams:\\\\n',\n            IFNULL(ARRAY_TO_STRING(diagram_descriptions, '\\\\n'), '')\n          ) AS prompt\n        FROM\n          `{project_id}.patent_analysis.ai_text_extraction`\n        WHERE\n          extracted_abstract_en IS NOT NULL\n      ),\n      STRUCT(\n        '''{schema}''' AS output_schema\n      )\n    ) AS t\n);\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T14:42:47.327061Z","iopub.execute_input":"2025-08-17T14:42:47.327366Z","iopub.status.idle":"2025-08-17T14:45:03.071373Z","shell.execute_reply.started":"2025-08-17T14:42:47.327327Z","shell.execute_reply":"2025-08-17T14:45:03.070349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization\n\n### Strategic Patent Portfolio Analysis\n\nThis chart provides a strategic overview of the patent applicants in our dataset. Each bubble represents a single applicant.\n\n---\n#### How to Read This Graph:\n\n* **Innovation Breadth (Horizontal Axis):** This measures how diverse an applicant's portfolio is. A position further to the right means the company has filed patents across a wider range of different technical domains.\n\n* **Average Complexity (Vertical Axis):** This is a proxy for how complex an applicant's inventions are. A higher position means their patents, on average, have a greater number of technical **components** as extracted by our AI.\n\n* **Bubble Size:** The size of each bubble corresponds to the **total number of patents** that applicant has in this dataset.\n\n---\n#### What It Tells Us:\n\nThis visualization helps us quickly identify different types of innovators. For example, a large bubble high up on the chart represents a major player creating complex inventions, while a small bubble far to the right might represent a nimble innovator exploring many different fields.","metadata":{}},{"cell_type":"code","source":"# This query creates a summary table for each patent applicant.\nsql_query = f\"\"\"\nWITH applicant_data AS (\n  SELECT\n    T1.applican,\n    T2.invention_domain,\n    ARRAY_LENGTH(T2.components) AS component_count\n  FROM\n    `{project_id}.patent_analysis.ai_text_extraction` AS T1\n  JOIN\n    `{project_id}.patent_analysis.patent_knowledge_graph` AS T2\n  ON\n    T1.uri = T2.uri\n  WHERE\n    T1.applican IS NOT NULL AND T2.invention_domain IS NOT NULL\n)\n\nSELECT\n  applican,\n  COUNT(DISTINCT invention_domain) AS innovation_breadth,\n  ROUND(AVG(component_count), 2) AS average_complexity,\n  COUNT(applican) AS total_patents\nFROM\n  applicant_data\nGROUP BY\n  applican\nHAVING\n  COUNT(applican) > 1\nORDER BY\n  total_patents DESC;\n\"\"\"\n\ndf_summary = client.query(sql_query).to_dataframe()\n\nfig = px.scatter(\n    df_summary,\n    x=\"innovation_breadth\",\n    y=\"average_complexity\",\n    size=\"total_patents\",          \n    color=\"applican\",              \n    hover_name=\"applican\",        \n    log_x=True,                    \n    size_max=60,                   \n    title=\"<b>Strategic Patent Portfolio Analysis: Breadth vs. Complexity</b>\",\n    labels={\n        \"innovation_breadth\": \"Innovation Breadth (Number of Domains)\",\n        \"average_complexity\": \"Average Invention Complexity (Number of Components)\"\n    }\n)\n\n# Customize the layout for a professional look\nfig.update_layout(\n    showlegend=False,\n    xaxis_title=\"<b>Innovation Breadth ‚û°Ô∏è</b> (More Diverse)\",\n    yaxis_title=\"<b>Average Complexity ‚¨ÜÔ∏è</b> (More Complex)\"\n)\n\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T19:11:56.042838Z","iopub.execute_input":"2025-08-19T19:11:56.043147Z","iopub.status.idle":"2025-08-19T19:11:56.142613Z","shell.execute_reply.started":"2025-08-19T19:11:56.043123Z","shell.execute_reply":"2025-08-19T19:11:56.141211Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3767906642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mARRAY_LENGTH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mcomponent_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mFROM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;31m`\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatent_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mai_text_extraction\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mT1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mJOIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatent_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatent_knowledge_graph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mT2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'project_id' is not defined"],"ename":"NameError","evalue":"name 'project_id' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"# Patent Insights with SQL Analysis\n\n## What did we build?\n\nNow that we have transformed the unstructured patent data into a structured Knowledge Graph, we can finally ask it complex questions.\n\n## Why is this important?\n- This is the payoff. \n- We will run queries that are impossible to perform on the original text.\n- Uncovering quantifiable insights about:\n  - Invention complexity\n  - Common design patterns across the entire dataset\n- Proves the value of the data transformation pipeline.\n\n## What will we find?\nWe will perform two types of analysis:\n\n1. **Quantitative Analysis**:\n   - Compare the average number of components across different technical domains\n   - Measure and rank their complexity\n\n2. **Architectural Pattern Mining**:\n   - `UNNEST` the component data\n   - Finds the most common \"building blocks\" and design patterns connected to any component we choose.","metadata":{}},{"cell_type":"code","source":"# Quantitative Analysis.\n\nsql_query = f\"\"\"\nSELECT\n  invention_domain,\n  COUNT(uri) AS number_of_patents,\n  ROUND(AVG(ARRAY_LENGTH(components)), 2) AS average_components,\n  MIN(ARRAY_LENGTH(components)) AS min_components,\n  MAX(ARRAY_LENGTH(components)) AS max_components\nFROM\n  `{project_id}.patent_analysis.patent_knowledge_graph`\nWHERE\n  ARRAY_LENGTH(components) > 0\nGROUP BY\n  invention_domain\nORDER BY\n  average_components DESC;\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")\n\ndf = job.to_dataframe()\ndf[df['number_of_patents'] >= 4]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:22:38.422342Z","iopub.execute_input":"2025-08-19T10:22:38.426209Z","iopub.status.idle":"2025-08-19T10:22:40.099875Z","shell.execute_reply.started":"2025-08-19T10:22:38.426085Z","shell.execute_reply":"2025-08-19T10:22:40.098822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Architectural Pattern Mining.\n\nsearching_topic = \"server\"\n\nsql_query = f\"\"\"\nWITH\n  patent_components AS (\n    SELECT\n      t.uri,\n      c.component_name,\n      c.connected_to\n    FROM\n      `{project_id}.patent_analysis.patent_knowledge_graph` AS t,\n      UNNEST(t.components) AS c\n  ),\n\n  component_connections AS (\n    SELECT\n      pc.uri,\n      pc.component_name,\n      connected_component\n    FROM\n      patent_components AS pc,\n      UNNEST(pc.connected_to) AS connected_component\n  )\n\nSELECT\n  connected_component,\n  COUNT(connected_component) AS connection_count\nFROM\n  component_connections\nWHERE\n  REGEXP_CONTAINS(component_name, r'(?i){searching_topic}')\nGROUP BY\n  connected_component\nORDER BY\n  connection_count DESC\nLIMIT 10;\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")\n\ndf = job.to_dataframe()\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:23:03.231043Z","iopub.execute_input":"2025-08-19T10:23:03.231640Z","iopub.status.idle":"2025-08-19T10:23:04.427778Z","shell.execute_reply.started":"2025-08-19T10:23:03.231612Z","shell.execute_reply":"2025-08-19T10:23:04.426856Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Patent Search Engine\n\n## What did we build?\nA powerful semantic search engine that finds specific technical components based on a natural language description of their function.\n\n## Why is this important?\n- Standard search finds keywords. This search finds meaning.\n- By combining two different vector embeddings, the engine understands patent's components and the technical context in which it operates.\n- This allows an engineer to find a \"valve for precise fluid delivery\" and get results from relevant medical patents, not car engine patents.\n\n## How did we do it?\nThe process involves three key stages, all performed within BigQuery:\n\n1. **Dual Embeddings**:\n   - We first generate two separate vector embeddings:\n     - One for the high-level patent context (title, abstract, domain, diagrams)\n     - Another for the specific component's function\n\n2. **Vector Combination**:\n   - We then create a custom User-Defined Function (UDF) to mathematically average these two vectors.\n   - This creates a single, final vector for each component that is rich with both specific and contextual meaning.\n\n3. **Semantic Search**:\n   - Finally, we use the `VECTOR_SEARCH` function to compare a user's query against these combined vectors.\n   - Returns the most similar components from the entire dataset.\n","metadata":{}},{"cell_type":"code","source":"# Create a remote connection for our embedding model\nsql_query = f\"\"\"\nCREATE OR REPLACE MODEL `{project_id}.patent_analysis.embedding_model`\n  REMOTE WITH CONNECTION `{location}.llm-connection`\n  OPTIONS (endpoint = 'gemini-embedding-001');\n\"\"\"\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This query creates a flat table of all components from all patents.\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.patent_components_flat` AS (\n  SELECT\n    t.uri,\n    t.invention_domain,\n    c.component_name,\n    c.component_function,\n    c.connected_to\n  FROM\n    `{project_id}.patent_analysis.patent_knowledge_graph` AS t,\n    UNNEST(t.components) AS c\n  WHERE\n    c.component_function IS NOT NULL\n    AND c.component_name IS NOT NULL\n);\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T07:15:09.091441Z","iopub.execute_input":"2025-08-19T07:15:09.091820Z","iopub.status.idle":"2025-08-19T07:15:11.657250Z","shell.execute_reply.started":"2025-08-19T07:15:09.091790Z","shell.execute_reply":"2025-08-19T07:15:11.656351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This query creates a single context vector for each patent, reading from ai_text_extraction table.\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.patent_context_embeddings` AS (\n  SELECT\n    t.uri,\n    t.ml_generate_embedding_result AS patent_context_vector\n  FROM\n    ML.GENERATE_EMBEDDING(\n      MODEL `{project_id}.patent_analysis.embedding_model`,\n      (\n        SELECT\n          uri,\n          CONCAT(\n            'Patent Title: ', IFNULL(extracted_title_en, ''), '\\\\n\\\\n',\n            'Applicant: ', IFNULL(applican, ''), '\\\\n\\\\n',\n            'International Classification: ', IFNULL(class_international, ''), '\\\\n\\\\n',\n            'Abstract: ', IFNULL(extracted_abstract_en, ''), '\\\\n\\\\n',\n            'Diagram Descriptions: ', IFNULL(ARRAY_TO_STRING(diagram_descriptions, '\\\\n'), '')\n          ) AS content\n        FROM\n          `{project_id}.patent_analysis.ai_text_extraction`\n        WHERE\n          extracted_title_en IS NOT NULL\n      )\n    ) AS t\n);\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T08:31:52.746631Z","iopub.execute_input":"2025-08-19T08:31:52.746949Z","iopub.status.idle":"2025-08-19T08:32:00.179224Z","shell.execute_reply.started":"2025-08-19T08:31:52.746928Z","shell.execute_reply":"2025-08-19T08:32:00.178306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This query creates a single specific function vector for each individual component.\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.component_function_embeddings` AS (\n  SELECT\n    t.uri,\n    t.component_name,\n    t.ml_generate_embedding_result AS component_function_vector\n  FROM\n    ML.GENERATE_EMBEDDING(\n      MODEL `{project_id}.patent_analysis.embedding_model`,\n      (\n        SELECT\n          uri,\n          component_name,\n          CONCAT(\n            'A component named \"', component_name, '\" whose function is to ', component_function\n          ) AS content\n        FROM\n          `{project_id}.patent_analysis.patent_components_flat`\n      )\n    ) AS t\n);\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T08:50:14.741042Z","iopub.execute_input":"2025-08-19T08:50:14.741836Z","iopub.status.idle":"2025-08-19T08:50:29.759562Z","shell.execute_reply.started":"2025-08-19T08:50:14.741777Z","shell.execute_reply":"2025-08-19T08:50:29.758737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This creates a UDF (user defined function), a helper function for averaging the previous two vectors that we created.\nsql_query = f\"\"\"\nCREATE OR REPLACE FUNCTION `{project_id}.patent_analysis.VECTOR_AVG`(vec1 ARRAY<FLOAT64>, vec2 ARRAY<FLOAT64>)\n    RETURNS ARRAY<FLOAT64>\n    LANGUAGE js AS r'''\n      if (!vec1 || !vec2 || vec1.length !== vec2.length) {{\n        return null;\n      }}\n      let avg_vec = [];\n      for (let i = 0; i < vec1.length; i++) {{\n        avg_vec.push((vec1[i] + vec2[i]) / 2.0);\n      }}\n      return avg_vec;\n    ''';\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T09:11:05.747270Z","iopub.execute_input":"2025-08-19T09:11:05.747567Z","iopub.status.idle":"2025-08-19T09:11:06.940964Z","shell.execute_reply.started":"2025-08-19T09:11:05.747548Z","shell.execute_reply":"2025-08-19T09:11:06.940091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This query joins all data and creates the final, context-aware combined vector.\nsql_query = f\"\"\"\nCREATE OR REPLACE TABLE `{project_id}.patent_analysis.component_search_index` AS (\n  SELECT\n    flat.uri,\n    flat.component_name,\n    flat.component_function,\n    `{project_id}.patent_analysis.VECTOR_AVG`(\n      ctx.patent_context_vector,\n      func.component_function_vector\n    ) AS combined_vector\n  FROM\n    `{project_id}.patent_analysis.patent_components_flat` AS flat\n  JOIN\n    `{project_id}.patent_analysis.patent_context_embeddings` AS ctx\n  ON\n    flat.uri = ctx.uri\n  JOIN\n    `{project_id}.patent_analysis.component_function_embeddings` AS func\n  ON\n    flat.uri = func.uri AND flat.component_name = func.component_name\n);\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T09:12:54.089760Z","iopub.execute_input":"2025-08-19T09:12:54.090507Z","iopub.status.idle":"2025-08-19T09:13:06.564847Z","shell.execute_reply.started":"2025-08-19T09:12:54.090479Z","shell.execute_reply":"2025-08-19T09:13:06.564042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"searching_prompt = \"I want a similar patent to a small network IOT device\"\n\nsql_query = f\"\"\"\nSELECT\n  base.uri,\n  base.component_name,\n  base.component_function,\n  distance\nFROM\n  VECTOR_SEARCH(\n    TABLE `{project_id}.patent_analysis.component_search_index`,\n    'combined_vector',\n    (\n      SELECT ml_generate_embedding_result\n      FROM ML.GENERATE_EMBEDDING(\n        MODEL `{project_id}.patent_analysis.embedding_model`,\n        (SELECT '{searching_prompt}' AS content)\n      )\n    ),\n    top_k => 7\n  )\n\"\"\"\n\njob = client.query(sql_query)\ntry:\n    job.result()\nexcept Exception as e:\n    print(f\"‚ùå FAILED: The query failed. Error:\\n\\n{e}\")\n\ndf = job.to_dataframe()\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:37:42.122281Z","iopub.execute_input":"2025-08-19T14:37:42.122822Z","iopub.status.idle":"2025-08-19T14:37:45.634898Z","shell.execute_reply.started":"2025-08-19T14:37:42.122785Z","shell.execute_reply":"2025-08-19T14:37:45.633982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def style_search_results(results_df: pd.DataFrame, search_query: str):\n    \"\"\"\n    Takes a DataFrame of search results and returns a styled HTML table\n    for clear and compelling presentation.\n    \"\"\"\n    if results_df.empty:\n        print(\"‚ö†Ô∏è The search returned no results.\")\n        return None\n\n    # Create a copy to avoid modifying the original DataFrame\n    styled_df = results_df.copy()\n\n    # --- Apply Formatting and Styling ---\n\n    # 1. Make the URI a clickable link\n    styled_df['uri'] = styled_df['uri'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x.split(\"/\")[-1]}</a>')\n\n    # 2. Format the distance column\n    styled_df['distance'] = styled_df['distance'].map('{:.4f}'.format)\n\n    # 3. Use the Pandas Styler to add advanced formatting\n    styler = styled_df.style \\\n        .set_caption(f\"<h3>Top 5 Component Matches for: '{search_query}'</h3>\") \\\n        .set_properties(**{\n            'text-align': 'left',\n            'white-space': 'normal', # Allow text wrapping\n            'font-size': '14px',\n            'font-family': 'Arial, sans-serif'\n        }) \\\n        .set_table_styles([\n            {'selector': 'th', 'props': [('text-align', 'left'), ('font-size', '16px')]},\n            {'selector': 'caption', 'props': [('caption-side', 'top'), ('font-size', '18px')]}\n        ]) \\\n        .hide(axis='index') \\\n        .background_gradient(subset=['distance'], cmap='RdYlGn_r') # Green for low distance, Red for high\n\n    return styler\n\nstyled_table = style_search_results(df, searching_prompt)\ndisplay(HTML(styled_table.to_html()))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T14:37:49.823944Z","iopub.execute_input":"2025-08-19T14:37:49.824274Z","iopub.status.idle":"2025-08-19T14:37:49.849437Z","shell.execute_reply.started":"2025-08-19T14:37:49.824251Z","shell.execute_reply":"2025-08-19T14:37:49.848251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T21:11:05.896785Z","iopub.execute_input":"2025-08-19T21:11:05.897070Z","iopub.status.idle":"2025-08-19T21:11:05.903735Z","shell.execute_reply.started":"2025-08-19T21:11:05.897048Z","shell.execute_reply":"2025-08-19T21:11:05.902438Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<img src=\"https://github.com/veyselserifoglu/bq-ai-patent-analyst/blob/main/doc/Patent%20Analysis%20Pipeline%20Architecture%20-%20PNG.png?raw=true\" width=\"800\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}